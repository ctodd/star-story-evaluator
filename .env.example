# API Provider: BEDROCK or ANTHROPIC (defaults to BEDROCK)
API_PROVIDER=BEDROCK

# AWS Bedrock Configuration
AWS_REGION=us-east-1
AWS_REGION=us-west-2

# Available Claude 3.x models on Bedrock:
# For Claude 3.0 models, use the model ID directly:
# BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
# BEDROCK_MODEL=anthropic.claude-3-haiku-20240307-v1:0
# BEDROCK_MODEL=anthropic.claude-3-opus-20240229-v1:0
#
# For Claude 3.5/3.7 models, the system will automatically use the correct inference profile ID
# BEDROCK_MODEL=us.anthropic.claude-3-5-sonnet-20240620-v1:0
# BEDROCK_MODEL=us.anthropic.claude-3-5-sonnet-20241022-v2:0
# BEDROCK_MODEL=us.anthropic.claude-3-5-haiku-20241022-v1:0
# BEDROCK_MODEL=us.anthropic.claude-3-7-sonnet-20250219-v1:0
BEDROCK_MODEL=us.anthropic.claude-3-sonnet-20240229-v1:0

# Use Converse API instead of InvokeModel (true/false)
USE_CONVERSE_API=false

# Anthropic Direct API Configuration (only needed if API_PROVIDER=ANTHROPIC)
# ANTHROPIC_API_KEY=your_api_key_here
# Available Claude 3.x models via direct API:
# ANTHROPIC_MODEL=claude-3-opus-20240229
# ANTHROPIC_MODEL=claude-3-sonnet-20240229
# ANTHROPIC_MODEL=claude-3-haiku-20240307
# ANTHROPIC_MODEL=claude-3-5-sonnet-20240620
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# ANTHROPIC_MODEL=claude-3-5-haiku-20241022
# ANTHROPIC_MODEL=claude-3-7-sonnet-20250219

# Debug mode (true/false)
DEBUG=false

# Server port
PORT=3000
